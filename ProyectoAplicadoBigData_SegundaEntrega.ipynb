{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Robert-Gomez-AI/HeartFailure/blob/main/ProyectoAplicadoBigData_SegundaEntrega.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = \"https://drive.google.com/uc?export=view&id=110NHJ-qD3Maf3x2GX8ngyEREwaBjKpuo\" alt = \"Encabezado MLDS\" width = \"100%\">  </img>"
      ],
      "metadata": {
        "id": "2qrgS_sCJquS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9669dfd"
      },
      "source": [
        "# **Definición e implementación de las tecnologías**\n",
        "---\n",
        "\n",
        "Este notebook es una plantilla que le puede servir como guía para el segundo entregable del proyecto aplicado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9T83K4_xNn8"
      },
      "source": [
        "# **Integrantes**\n",
        "---\n",
        "\n",
        "- Daniela Mejia\n",
        "- Yohjan Roldan\n",
        "- Robert Gomez"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6de2158"
      },
      "source": [
        "## **1. Tecnologías a utilizar**\n",
        "---\n",
        "\n",
        "Se debe proporcionar una justificación sólida para la elección de las tecnologías específicas que se utilizarán en el proyecto de *Big Data*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20031c7b"
      },
      "source": [
        "### **1.1. Selección de tecnologías**\n",
        "---\n",
        "\n",
        "- ¿Cuáles son las tecnologías seleccionadas para el proyecto?\n",
        "- ¿Por qué se eligieron estas tecnologías en lugar de otras alternativas?\n",
        "- ¿Cómo se alinean las tecnologías seleccionadas con los objetivos del proyecto?\n",
        "- ¿Cuáles son las ventajas clave de cada tecnología seleccionada?\n",
        "- ¿Existen desventajas o limitaciones que deben ser abordadas?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b0f9910"
      },
      "source": [
        "### **Introducción al proyecto**\n",
        "Para el proyecto  se han seleccionado un conjunto de tecnologías que se alinean con los objetivos del mismo y ofrecen ventajas clave en términos de facilidad de uso, rendimiento y flexibilidad.\n",
        "\n",
        "1.   Tecnologías seleccionadas\n",
        "* Las principales tecnologías seleccionadas para este proyecto son:\n",
        "* Lenguaje de programación: Python\n",
        "* Bibliotecas de procesamiento de lenguaje natural (NLP): NLTK, spaCy\n",
        "* Bibliotecas de aprendizaje computacional: scikit-learn, TensorFlow, PyTorch\n",
        "* Google Colab para el desarrollo colaborativo y la ejecución de código en la nube\n",
        "\n",
        "2. Beneficios de las Tecnologías Seleccionadas:\n",
        "\n",
        "  2.1. Python: Es un lenguaje de programación ampliamente utilizado en la comunidad de ciencia de datos y aprendizaje automático. Ofrece una gran cantidad de bibliotecas y una comunidad activa de desarrollo, lo que facilita la implementación de soluciones para el análisis de emociones.\n",
        "  \n",
        "  2.2. NLTK y spaCy: Estas bibliotecas de procesamiento de lenguaje natural proporcionan funcionalidades avanzadas, como tokenización, lematización y análisis gramatical, que son fundamentales para el análisis de texto y la extracción de características relevantes para el reconocimiento de emociones.\n",
        "\n",
        "  2.3. TensorFlow y PyTorch: Estos frameworks de aprendizaje profundo permiten implementar modelos complejos de análisis de sentimientos con alta eficiencia computacional. Esto es crucial para lograr una alta precisión en la clasificación de emociones en el conjunto de datos.\n",
        "\n",
        "  2.3.   Google Colab: Proporciona recursos de computación gratuitos en la nube y una interfaz colaborativa, lo que facilita el desarrollo y la experimentación del proyecto de análisis de emociones. Esto es especialmente útil cuando se trabaja con grandes volúmenes de datos y se requiere acceso a recursos de cómputo potentes.\n",
        "\n",
        "3. Alineación de las tecnologías seleccionadas con los objetivos del proyecto:\n",
        "\n",
        "Las tecnologías seleccionadas para este proyecto de análisis de emociones se alinean perfectamente con los objetivos.\n",
        "\n",
        "Python y las bibliotecas de procesamiento de lenguaje natural (NLP) como NLTK y spaCy ofrecen las herramientas necesarias para procesar y analizar el texto del conjunto de datos.\n",
        "\n",
        "Por otro lado, las bibliotecas de aprendizaje automático como TensorFlow y PyTorch permiten implementar modelos complejos de análisis de sentimientos con alta eficiencia computacional.\n",
        "\n",
        "Finalmente, Google Colab facilita el desarrollo colaborativo y el acceso a recursos de cómputo en la nube, lo que agiliza el proceso de experimentación y mejora del modelo.\n",
        "\n",
        "En resumen, el uso de estas tecnologías permite abordar de manera efectiva los objetivos del proyecto de análisis de emociones en el conjunto de datos proporcionado.\n",
        "\n",
        "4. Las tecnologías seleccionadas para el proyecto presentan ventajas significativas, pero también es importante considerar las posibles desventajas y limitaciones:\n",
        "\n",
        " * Python: Aunque es ampliamente utilizado, puede tener un rendimiento inferior en comparación con lenguajes compilados para tareas intensivas en cálculos.\n",
        " * NLTK y spaCy: Estas bibliotecas de procesamiento de lenguaje natural pueden necesitar ajustes y optimizaciones para manejar eficientemente grandes volúmenes de texto.\n",
        " * TensorFlow y PyTorch: Requieren un conocimiento profundo de conceptos de aprendizaje automático, lo que puede dificultar su configuración y entrenamiento.\n",
        " * Google Colab: A pesar de sus ventajas en el desarrollo colaborativo, puede tener restricciones en el uso de recursos computacionales y acceso a ciertas bibliotecas externas, lo que podría limitar algunas funcionalidades."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Instalación de Herramientas**\n",
        "---\n",
        "Debe describir el proceso de instalación de las herramientas y tecnologías seleccionadas e incluir los *scripts* utilizados para ello."
      ],
      "metadata": {
        "id": "qG-gA0MvzMTA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ¿Cuáles son las herramientas específicas que se instalarán en el entorno? ¿Por qué?\n",
        "- ¿Existen requisitos específicos del sistema para cada herramienta?\n",
        "- ¿Cómo se configurarán y personalizarán las herramientas para adaptarse a los requisitos específicos del proyecto?\n",
        "- ¿Existen configuraciones recomendadas para optimizar el rendimiento?"
      ],
      "metadata": {
        "id": "eWhhKe7HdrKA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Herramientas Específicas a Instalar:\n",
        "\n",
        "* Python\n",
        "* NLTK\n",
        "* spaCy\n",
        "* TensorFlow\n",
        "* PyTorch\n",
        "* Google Colab\n",
        "* MongoDB\n",
        "\n",
        "2. Requisitos Específicos del Sistema:\n",
        "Sistema operativo compatible con Python y las bibliotecas mencionadas.\n",
        "Espacio suficiente en disco para instalar Python y las bibliotecas.\n",
        "\n",
        "* Base de datos almacenada en MongoDB, para ello el dataset debe cumplir con los requerimientos de almacenamiento para la versión no paga de MongoDB. Es decir que preferiblemente usaremos un dataset de menos de 5GB. Sin embargo, en caso de que requiramos usar más espacio de almacenamiento o un mejor procesamiento, optaremos por contemplar otras alternativas.\n",
        "\n",
        "\n",
        "3. Configuración y Personalización:\n",
        "\n",
        "  3.1. Configurar un entorno virtual de Python para aislar las dependencias del proyecto.\n",
        "  \n",
        "  3.2. Instalar las bibliotecas utilizando pip o conda dentro del entorno virtual.\n",
        "\n",
        "  3.3. Descargar el conjunto de datos desde el URL proporcionado y almacenarlo localmente para su acceso durante el desarrollo.\n",
        "\n",
        "4. Scripts de Instalación:"
      ],
      "metadata": {
        "id": "sTGXhvF4_ROG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 1: Instalar Python y herramientas básicas de desarrollo:"
      ],
      "metadata": {
        "id": "-LS7lmsE-zjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar Python (puedes usar Anaconda para una instalación más completa)\n",
        "# Asegúrate de agregar Python al PATH del sistema durante la instalación."
      ],
      "metadata": {
        "id": "Zz43eObp-7UW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 2: Configurar un entorno virtual:"
      ],
      "metadata": {
        "id": "39razIT1-vAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un entorno virtual (ejemplo usando venv)\n",
        "# Activar el entorno virtual"
      ],
      "metadata": {
        "id": "m3ch-UXE-kbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 3: Instalar bibliotecas necesarias:"
      ],
      "metadata": {
        "id": "PYfnOi05-_wM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar bibliotecas de procesamiento de lenguaje natural y aprendizaje automático\n",
        "!pip install -U spacy\n",
        "\n",
        "!pip install nltk\n",
        "\n",
        "!pip install tensorflow\n",
        "\n",
        "!pip install torch\n",
        "\n",
        "!pip install -U scikit-learn\n",
        "\n",
        "#Instalar libreria para realizar las conexiones con la BD MongoDB\n",
        "!python -m pip install 'pymongo[srv]'"
      ],
      "metadata": {
        "id": "P9IyB-5T_EB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d64ec1c-3318-4682-87f6-130fdcb37981"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: pymongo[srv] in /usr/local/lib/python3.10/dist-packages (4.7.2)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo[srv]) (2.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 4: Importar librerias necesarias"
      ],
      "metadata": {
        "id": "6vJrNGRiGZsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementaremos numpy para el uso de herramientas como arreglos y matrices multidimencionales\n",
        "import numpy as np\n",
        "\n",
        "#Implementaremos Scikit-learn para tener la posibilidad de implementar los modelos de aprendizaje de maquina que esta libreria ofrece\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Implementamos pymongo y json para la interacción con la BD junto con el tratamiento de los objetos json que se desea utilizar para el tratamiento de los datos\n",
        "import pymongo\n",
        "from pymongo import MongoClient\n",
        "import json\n",
        "\n",
        "#Usaremos pandas para manipular los datos de forma tabular\n",
        "import pandas as pd\n",
        "\n",
        "#Usaremos las librerias y dependencias de procesamiento de texto y analisis de sentimiento\n",
        "import spacy\n",
        "\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import torch"
      ],
      "metadata": {
        "id": "ZfXcP6OMGdKd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Verificar versiones a utilizar\n",
        "print('Versiones de las librerias\\n')\n",
        "print('Numpy: '+np.__version__)\n",
        "print('Pandas: '+pd.__version__)\n",
        "print('Scikit-learn: '+sklearn.__version__)\n",
        "print('MongoClient: '+pymongo.__version__)\n",
        "print('json: '+json.__version__)\n",
        "print('spacy: '+spacy.__version__)\n",
        "print('nltk: '+nltk.__version__)\n",
        "print('tensorflow: '+tf.__version__)\n",
        "print('torch: '+torch.__version__)"
      ],
      "metadata": {
        "id": "QeJB9JH_LjR9",
        "outputId": "773f06a6-dcf9-4411-b9a1-43da8fad9359",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versiones de las librerias\n",
            "\n",
            "Numpy: 1.25.2\n",
            "Pandas: 2.0.3\n",
            "Scikit-learn: 1.4.2\n",
            "MongoClient: 4.7.2\n",
            "json: 2.0.9\n",
            "spacy: 3.7.4\n",
            "nltk: 3.8.1\n",
            "tensorflow: 2.15.0\n",
            "torch: 2.2.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Configuraciones Recomendadas: Configurar el entorno virtual con las versiones específicas de las bibliotecas para garantizar la reproducibilidad del proyecto.\n",
        "Utilizar GPU si está disponible para acelerar el entrenamiento de modelos de aprendizaje profundo (requiere configuración adicional de CUDA y cuDNN para TensorFlow y PyTorch)."
      ],
      "metadata": {
        "id": "xYLHxt41_ND4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Créditos**\n",
        "---\n",
        "\n",
        "* **Profesor:** [Jorge E. Camargo, PhD](https://dis.unal.edu.co/~jecamargom/)\n",
        "* **Asistentes docentes:**\n",
        "    - [Juan Sebastián Lara Ramírez](https://www.linkedin.com/in/juan-sebastian-lara-ramirez-43570a214/).\n",
        "* **Diseño de imágenes:**\n",
        "    - [Rosa Alejandra Superlano Esquibel](mailto:rsuperlano@unal.edu.co).\n",
        "* **Coordinador de virtualización:**\n",
        "    - [Edder Hernández Forero](https://www.linkedin.com/in/edder-hernandez-forero-28aa8b207/).\n",
        "    \n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ],
      "metadata": {
        "id": "2FLj-UiEd91C"
      }
    }
  ]
}